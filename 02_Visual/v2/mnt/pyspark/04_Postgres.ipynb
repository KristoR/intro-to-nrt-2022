{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca48ce6-2bdc-474a-a548-4fa5fdc43580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.3.3\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf84a66-8023-4f0b-ba40-9776773e31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"postgres\"\n",
    "port = \"5432\"\n",
    "user = \"myuser\"\n",
    "pw = \"MyPassw0rd!\" # never show your password \n",
    "db = \"visual\"\n",
    "schema = \"public\"\n",
    "tbl = \"stream_loc\" # you need to create this table on postgres beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837a887-0d5f-4082-96fb-379091b597cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (spark.read\n",
    "             .parquet(\"output/kafka_us.parquet/*.parquet\")\n",
    "            ).schema\n",
    "\n",
    "kafka_df = (spark.readStream\n",
    "     .format(\"parquet\")\n",
    "     .schema(schema)\n",
    "     .option(\"path\", \"output/kafka_us.parquet/*.parquet\")\n",
    "     .load()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aec88f-1f1e-4a92-a964-bb8ee9ed1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = \"\"\"\n",
    "STRUCT<gender: STRING,\n",
    "name: STRUCT<title: STRING,\n",
    "            first: STRING,\n",
    "            last: STRING>,\n",
    "location: STRUCT<street: STRUCT<number: INT,\n",
    "                                name: STRING>,\n",
    "                 city: STRING,\n",
    "                state: STRING,\n",
    "                country: STRING,\n",
    "                postcode: INT,\n",
    "                coordinates: STRUCT<latitude: STRING,\n",
    "                                    longitude: STRING>,\n",
    "                timezone: STRUCT<offset: STRING,\n",
    "                                description: STRING>\n",
    "                >,\n",
    "email: STRING,\n",
    "login: STRUCT< uuid: STRING,\n",
    "            username: STRING,\n",
    "            password: STRING,\n",
    "            salt: STRING,\n",
    "            md5: STRING,\n",
    "            sha1: STRING,\n",
    "            sha256: STRING>,\n",
    "dob: STRUCT<date: STRING,\n",
    "            age: INT>,\n",
    "registered: STRUCT<date: STRING,\n",
    "                    age: INT>,\n",
    "phone: STRING,\n",
    "cell: STRING,\n",
    "id: STRUCT<name: STRING,\n",
    "            value: STRING>,\n",
    "picture: STRUCT<large: STRING,\n",
    "                medium: STRING,\n",
    "                thumbnail: STRING>,\n",
    "nat: STRING,\n",
    "timestamp: STRING>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e595129-799d-4ad6-b1ea-dacf53b9b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = (kafka_df\n",
    "    .select(F.from_json(F.col(\"value\").cast(\"string\"), json_schema).alias(\"json\"),\n",
    "            F.col(\"timestamp\").alias(\"ts\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93675b3-593d-41e6-9c99-ee709b76dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df.createOrReplaceTempView(\"kafka\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21a038-8b94-4535-94bb-fb220d1835cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT CONCAT(json.name.first, ' ', json.name.last) as name,\n",
    "CAST(json.location.coordinates.latitude AS float) as latitude,\n",
    "CAST(json.location.coordinates.longitude AS float) as longitude\n",
    "FROM kafka\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9d51c-c1a5-47a2-8c51-29c60af789bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreach_batch_function(df_batch, epoch_id):\n",
    "    (df_batch.write.format(\"jdbc\") \n",
    "        .option(\"driver\", 'org.postgresql.Driver')\n",
    "        .option(\"url\", f\"jdbc:postgresql://{host}:{port}/{db}\") \n",
    "        .option(\"dbtable\", f\"{tbl}\") \n",
    "        .option(\"user\", user) \n",
    "        .option(\"password\", pw) \n",
    "        .mode(\"append\")\n",
    "        .save()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7f149-1be8-4b11-bdd3-dc54e8e9453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df.writeStream.outputMode(\"append\").foreachBatch(foreach_batch_function).start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7781eb-52cf-4c79-bb95-bc65bc1e91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86a545e9c7c8a04a9f5ab582097b4968329114428a3fde0cf520c5aeef29910b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
